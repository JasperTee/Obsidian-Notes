## 1. Conceptualising interaction
### 1. Mental Models

- **Definition**: A mental model is how users **think** and **believe** a system or device works.
    
- **Characteristics**:
    
    - **Personal** – each user forms their own mental model.
        
    - **Incomplete** – often based on limited experience, may be inaccurate.
        
    - **Dynamic** – changes over time as users gain new experiences.
        
- **Importance in design**:
    
    - Users act based on their mental models.
        
    - If their mental model does not match reality → confusion, mistakes, frustration.
        
    - Designers should align products with familiar mental models to make them easy to learn and use.
        
- **Examples**:
    
    - Pressing a pedestrian crossing button many times to make the light change faster → incorrect mental model.
        
    - Recovering deleted files from a computer “trash bin” → correct mental model (reflects real-world experience).
        

---

### 2. Conceptual Models

- **Definition**: A conceptual model is the **designer’s intended model** of how the system should work, communicated to users.
    
- **Role**:
    
    - Provides users with a **high-level understanding** of the system.
        
    - Shapes users’ mental models to be more accurate.
        
    - Makes systems more **intuitive and learnable**.
        
- **How it is conveyed**:
    
    - Through **interfaces, feedback, affordances, and metaphors**.
        
    - Uses language and concepts familiar to the target users.
        
- **Examples**:
    
    - Online shopping app: dragging products into a “shopping cart” → conceptual model matches the real-world mental model of shopping.
        
    - Calendar app: saving an appointment → matches users’ mental model of writing in a diary.
        

---

### 3. Interaction Types (Preece et al., 2015)

There are four main types of interactions:

1. **Instructing** – issuing commands (menus, keyboard shortcuts, voice commands).
    
    - Fast, efficient, good for repetitive tasks.
        
    - Example: “Print file,” “Send email.”
        
2. **Conversing** – interacting with the system as if having a conversation.
    
    - Used in chatbots, voice assistants.
        
    - Helpful for natural interaction and accessibility.
        
    - Example: Siri, Alexa, Google Assistant.
        
3. **Manipulating** – direct interaction with objects (drag, drop, resize, zoom).
    
    - Intuitive, hands-on.
        
    - Example: resizing a window, pinch-to-zoom on a smartphone.
        
4. **Exploring** – navigating through environments (physical or virtual).
    
    - Example: Google Maps Street View, VR with Oculus Rift, open-world games.
        

---

### 4. Relationship Between Mental Models, Conceptual Models, and Interaction

- **Mental Models** = what users believe about the system.
    
- **Conceptual Models** = what designers intend to communicate.
    
- **Interaction Types** = how users actually perform tasks with the system.
    
- If the conceptual model is well designed → users develop accurate mental models → interactions become smooth and effective.
## 2. Input and Output Technologies

### 1. Why are Input/Output important?

- Interaction with computers is a **feedback loop**:
    
    - Human actions (output) → System input.
        
    - System processing → System output → Human input.
        
- Choosing the right input and output devices affects:
    
    - **Efficiency** – can users complete their tasks effectively?
        
    - **Experience** – is the interaction smooth, enjoyable, meaningful?
        
    - **Accessibility** – does it suit people with different physical or cognitive abilities?
        

---

### 2. Input Devices

- **Definition**: A device (with software) that transforms user actions into data the system can process.
    
- **Functions**:
    
    - Issue instructions (commands).
        
    - Enter and register data.
        
    - Communicate user intentions in a way computers can interpret.
        

#### Examples

1. **Traditional input**:
    
    - Keyboards (physical, on-screen).
        
    - Pointing devices: mouse, joystick, trackpad, game controllers.
        
2. **Composite devices**:
    
    - Touchscreens, smartphones (combine input + output).
        
3. **Audio/voice input**:
    
    - Microphones, speech recognition, biometric voice verification.
        
4. **Imaging and sensors**:
    
    - Cameras, scanners, Kinect, motion sensors, EEG, eye-tracking, heat sensors.
        
5. **Specialized/assistive input**:
    
    - Foot mouse (for people with mobility limitations).
        
    - Eye-movement tracking (for people with disabilities).
        
    - Stephen Hawking’s infrared cheek switch.
        

#### Design Considerations

- Match **physiology** (hand size, motor skills, reach, strength).
    
- Match **cognitive abilities** (memory, attention).
    
- Fit **tasks and environment**:
    
    - Noisy environment → touch better than speech.
        
    - Sun glare → physical buttons better than screens.
        
- Support **safe, efficient, enjoyable** interactions.
    

---

### 3. Output Devices

- **Definition**: Convert computer data into forms perceivable by humans.
    
- **Traditional output**: was only visual (on screen/paper), now includes many modalities.
    

#### Examples

1. **Visual output**:
    
    - Screens, projectors, LED panels, AR/VR headsets.
        
2. **Auditory output**:
    
    - Speakers, headphones, voice feedback, chatbots.
        
3. **Haptic output**:
    
    - Vibrations, force feedback, robotic actuators, VR gloves.
        
4. **Tangible output**:
    
    - 3D printing, physical models (objects, organs, houses).
        
5. **Motion-based output**:
    
    - Robots, moving devices, mechanical systems.
        

#### Design Considerations

- Does it support the user’s **abilities** (e.g., audio output for visually impaired)?
    
- Does it match the **task/context** (e.g., auditory output while driving)?
    
- Does it improve **usability** by providing clear feedback?
    

---

### 4. Emerging Input/Output Technologies

- **Brain-Computer Interfaces (BCI)**:
    
    - e.g., Neuralink – implant chips that allow controlling a cursor or device using brain signals.
        
- **Wearable Sensors for Healthcare**:
    
    - Monitor vital signs + environment in real-time (IoT + telemedicine).
        
- **Bio-Digital Systems**:
    
    - Integration of biotechnology with digital tech → wearable laboratories to measure hormones, genomes, microbiomes.
        
- **Augmented & Mixed Reality Devices**:
    
    - Google Glass, Microsoft HoloLens, AR glasses, VR systems.